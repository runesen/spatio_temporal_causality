---
output:
  html_document: default
  pdf_document: default
---
<!--HOW TO COMPLETE THIS FORM:-->

<!--
1. Checkboxes in this document appear as follows: 

- [ ] This is a checkbox 

To check a checkbox, replace [ ] by [x], as follows: 

- [x] This is a checked checkbox 

Note that current versions of RStudio for Mac (this will change with RStudio versions 1.3 and higher) will not create a formatted checkbox but will leave the original characters, i.e., literally "[ ]" or "[x]". It's fine to submit a PDF in this form.
 
2. For text answers, simply type the relevant text in the areas indicated. A blank line starts a new paragraph. 
 
3. Comments (like these instructions) provide additional instructions throughout the form. There is no need to remove them; they will not appear in the compiled document. 

4. If you are comfortable with Markdown syntax, you may choose to include any Markdown-compliant formatting in the form. For example, you may wish to include R code chunks and compile this document in R Markdown.
-->

This folder contains data and reproducing scripts for the manuscript
“Towards Causal Inference for Spatio-Temporal Data: Conflict and Forest Loss in Colombia”
submitted to JASA Case Studies on May 26 2020


# Part 1: Data

- [ ] This paper does not involve analysis of external data (i.e., no data are used or the only data are generated by the authors via simulation in their code).

<!--
If box above is checked and if no simulated/synthetic data files are provided by the authors, please skip directly to the Code section. Otherwise, continue.
-->

- [x] I certify that the author(s) of the manuscript have legitimate access to and permission to use the data used in this manuscript.

<!-- If data are simulated using random number generation, please be sure to set the random number seed in the code you provide -->

## Abstract

<!--
Provide a short (< 100 words), high-level description of the data
-->

The data consist of four data sets, all of which are publicly available: 

1. Forest loss (remote sensing based spatio-temporal data set)
2. Conflict events (georeferenced spatio-temporal data set, based on reports from newspapers and NGOs)
3. Distance to road (Euclidean distance to the closest road calculated based on a vector-based road-dataset)
4. Population density (gloal population density dataset, temporally explicit at a 5-year resolution)

From the above primary data sets, we generate a single summary data set
on which most of our analysis is based. It can be found in the supplementary
materials under the filename data_xy_colombia_20200616.txt.

## Availability


- [x] Data **are** publicly available.
- [ ] Data **cannot be made** publicly available.

If the data are publicly available, see the *Publicly available data* section. Otherwise, see the *Non-publicly available data* section, below.

### Publicly available data

- [x] Data are available online at:
1. https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.6.html
2. https://ucdp.uu.se/downloads/index.html#ged_global
3. http://biogeo.ucdavis.edu/data/diva/rds/COL_rds.zip
4. https://sedac.ciesin.columbia.edu/data/set/gpw-v4-population-density-rev11/data-download

- [x] Data are available as part of the paper’s supplementary material.

- [ ] Data are publicly available by request, following the process described here:

- [ ] Data are or will be made available through some other mechanism, described here:


<!-- If data are available by request to the authors or some other data owner, please make sure to explain the process of requesting access to the data. -->

### Non-publicly available data

<!--
The Journal of the American Statistical Association requires authors to make data accompanying their papers available to the scientific community except in cases where: 1) public sharing of data would be impossible, 2) suitable synthetic data are provided which allow the main analyses to be replicated (recognizing that results may differ from the "real" data analyses), and 3) the scientific value of the results and methods outweigh the lack of reproducibility.

Please discuss the lack of publicly available data. For example:
-	why data sharing is not possible,
-	what synthetic data are provided, and 
-	why the value of the paper's scientific contribution outweighs the lack of reproducibility.
-->

## Description

### File format(s)

<!--
Check all that apply
-->
- [x] CSV or other plain text.
- [ ] Software-specific binary format (.Rda, Python pickle, etc.): pkcle
- [ ] Standardized binary format (e.g., netCDF, HDF5, etc.): 
- [x] Other (please specify): .vrt, SHP, SHP

### Data dictionary

<!--
A data dictionary provides information that allows users to understand the meaning, format, and use of the data.
-->

- [x] Provided by authors in the following file(s): data_dictionary.txt
- [ ] Data file(s) is(are) self-describing (e.g., netCDF files)
- [ ] Available at the following URL: 

### Additional Information (optional)

<!-- 
OPTIONAL: Provide any additional details that would be helpful in understanding the data. If relevant, please provide unique identifier/DOI/version information and/or license/terms of use.
-->

# Part 2: Code

## Abstract

<!--
Provide a short (< 100 words), high-level description of the code. If necessary, more details can be provided in files that accompany the code.
-->

## Description

### Code format(s)

<!--
Check all that apply
-->
- [x] Script files
    - [x] R
    - [x] Python
    - [ ] Matlab
    - [ ] Other: 
- [ ] Package
    - [ ] R
    - [ ] Python
    - [ ] MATLAB toolbox
    - [ ] Other: 
- [ ] Reproducible report 
    - [ ] R Markdown
    - [ ] Jupyter notebook
    - [ ] Other:
- [ ] Shell script
- [ ] Other (please specify): 

### Supporting software requirements

R, Python, ArcGIS

#### Version of primary software used

<!--
(e.g., R version 3.6.0)
-->

R version 3.6.1 (2019-07-05), Python version 3.7, ArcGIS Version 10.5

#### Libraries and dependencies used by the code

<!--
Include version numbers (e.g., version numbers for any R or Python packages used)
-->

In our R scripts, we used the following packages

* ggplot2 (version 3.2.1)
* foreach (version 1.4.7)
* gridExtra (version 2.3)
* reshape2 (version 1.4.3)
* viridis (version 0.5.1)
* fields (version 10.0)
* dplyr (version 0.8.3)

In our Python scripts, we used the following packages

* gdal (version 3.0.2)
* osr (version 3.0.2)
* ogr (version 3.0.2)
* numpy (version 1.18.1)
* joblib (version 0.15.1)
* tqdm (version 4.46.0)
* urllib3 (version 1.25.8)

### Supporting system/hardware requirements (optional)

<!--
OPTIONAL: System/hardware requirements including operating system with version number, access to cluster, GPUs, etc.
-->

### Parallelization used

- [ ] No parallel code used
- [x] Multi-core parallelization on a single machine/node
    - Number of cores used: 8
- [x] Multi-machine/multi-node parallelization 
    - Number of nodes and cores used: 3 nodes, 243 cores

### License

- [ ] MIT License (default)
- [ ] BSD 
- [ ] GPL v3.0
- [x] Creative Commons
- [ ] Other: (please specify below)


### Additional information (optional)

<!--
OPTIONAL: By default, submitted code will be published on the JASA GitHub repository (http://github.com/JASA-ACS) as well as in the supplementary material. Authors are encouraged to also make their code available in a public repository. If relevant, please provide unique identifier/DOI/version information.-->

# Part 3: Reproducibility workflow

<!--
The materials provided should provide a straightforward way for reviewers and readers to reproduce analyses with as few steps as possible. 
-->

## Scope

The provided workflow reproduces:

- [x] Any numbers provided in text in the paper
- [ ] All tables and figures in the paper
- [x] Selected tables and figures in the paper, as explained and justified below:

## Workflow

### Format(s)

<!--
Check all that apply
-->
- [ ] Single master code file 
- [ ] Wrapper (shell) script(s)
- [ ] Self-contained R Markdown file, Jupyter notebook, or other literate programming approach
- [ ] Text file (e.g., a readme-style file) that documents workflow
- [ ] Makefile
- [x] Other (more detail in *Instructions* below)

### Instructions

<!--
Describe how to use the materials provided to reproduce analyses in the manuscript. Additional details can be provided in file(s) accompanying the reproducibility materials.
-->

#### Summary data set

We first describe how to generate the summary data set data_xy_colombia_20200616.txt.
from the publicly avaible data sets mentioned above. 

1. Run 00_Download_ForestLossData.py, which downloads the forest loss data from 
https://earthenginepartners.appspot.com/science-2013-global-forest/download_v1.6.html
and saves it to the files Forest2000.vrt, Gain.vrt, and LossYear.vrt.
2. Run script 01_ForestLoss_Summaries.py, which summarizes the data to 10x10km grid cells and saves it to
Hansen_Summaries_ALL_20190821.csv. 
3. Download the conflict data from 
https://ucdp.uu.se/downloads/index.html#ged_global
(choose ”UCDP Georeferenced Event Dataset (GED) Global version 19.1” in SHX format)
save it to a file anmed ged181.shp. 
4. Run 02_Conflict-Summaries.py, which then summarizes the data to 10x10km grid cells and saves it to
PRIO-summaries_bestEstimate_20191217.
5. Download the road data for Colombia from http://biogeo.ucdavis.edu/data/diva/rds/COL_rds.zip
6. Run Script 03_CalculateDistanceToRoad.py, which calculates the Euclidean distance to roads at 1km spatial resolution and stores the data to DistanceToRoad_1km.tif (caution: modify the workFolder in the script header)
7. Run Script 04_RoadDist_Summaries.py, which aggregates DistanceToRoad_1km.tif to 10x10km grid cells, and saves it to RoadDist_Summaries.csv
8. Download the population density data, for each of the years 2000, 2005, 2010, 2015 from
https://sedac.ciesin.columbia.edu/data/set/gpw-v4-population-density-rev11/data-download
(choose Temporal: Single Year, FileFormat: Geo Tiff, Resolution: 30 seconds (approx. 1km))
and save it to files named
gpw_v4_population_density_rev10_2000_30_sec.tif
gpw_v4_population_density_rev10_2005_30_sec.tif
gpw_v4_population_density_rev10_2010_30_sec.tif
gpw_v4_population_density_rev10_2015_30_sec.tif
9. Run	05_Population-Summaries.py, which summarizes the data to 10x10km grid cells and saves it to
GPWv4_summary_20190129.csv
10. Run merge_data.R, which takes as input the following five data sets and generates the summary data set data_xy_colombia_20200616.txt.
    + Hansen_Summaries_ALL_20190821.csv
    + PRIO-summaries_bestEstimate_20191217
    + RoadDist_Summaries.csv
    + GPWv4_summary_20190129.csv
    + uniqueID_country_Biome_LS_Anthrome_20190130.csv 


#### Figures

Apart from Figures 1 and 5, all our figures can be generated from the data set 
data_xy_colombia_20200327.txt by running corresponding R scripts.

* Figure 1 (temporally aggregated summary of data set): 
    + Run construct_summary_dataset.R, which generates the file data_xy_colombia_temporally_aggregated_20200616.txt
    + Layers were visually assembled in ArcMAp 10.5
* Figure 2 (conceptual idea for estimating causal effects from obs. data): run concept.R 
* Figure 3 (simulation experiment): run CSTM_example_consistency.R
* Figure 4 (results of resampling test on country level): run resampling_sim.R and resampling_plot.R
* Figure 5 (regional summaries, causal effects and FARC presence): 
    + run construct_summary_dataset.R, which generates the file data_xy_colombia_regional_summaries_20200432.txt 
    + run regional_effects.R, which generates the file regional_effects.txt 
    + data on FARC presence stem from: https://pares.com.co/2015/04/24/los-mapas-del-conflicto/
    + Layers were visually assembled in ArcMAp 10.5
* Figure 6 (Colombian peace process): run peace_agreement.R
* Figure 7 (Plot illustrating example in remark): run plot_remark.R
* Figure 8 (Spatial block-premutation scheme): run spatial_blockresampling.R


#### Results

All results on test statistics and p-values stated in our 
manuscript can be reproduced from data_xy_colombia_20200327.txt
using the below scripts.

* instantaneous effects, standard resampling: run resampling_sim.R
* temorally lagged effects, standard resampling: run resampling_tlag1.R
* instantaneous effects, temporal block-resampling: run blockresampling.R
* temorally lagged effects, temporal block-resampling: run blockresampling_tlag1.R
* instantaneous effects, spatial block-resampling: run spatial_blockresampling.R

### Expected run-time

Approximate time needed to reproduce the analyses on a standard desktop machine:

- [ ] < 1 minute
- [ ] 1-10 minutes
- [ ] 10-60 minutes
- [x] 1-8 hours
- [ ] > 8 hours
- [ ] Not feasible to run on a desktop machine, as described here:

